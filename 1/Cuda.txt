// Modified version of code found here:
// https://www.olcf.ornl.gov/tutorials/cuda-vector-addition/
#include <assert.h>
#include <math.h>
#include <stdio.h>
#include <stdlib.h>
#include <time.h>

// CUDA kernel. Each thread takes care of one element of c array
__global__ void vecAdd(float *a, float *b, float *c, unsigned n) {
  // Get our global thread ID
  int id = blockIdx.x * blockDim.x + threadIdx.x;

  // Make sure we do not go out of bounds
  if (id < n)
    c[id] = a[id] + b[id];
}

int main(int argc, char *argv[]) {
  // Size of vectors
  unsigned N = (argc > 1 ? atoi(argv[1]) : 1000000);
  unsigned trials = (argc > 2 ? atoi(argv[2]) : 1000);

  // Host input,outut vectors
  float *h_a, *h_b, *h_c;

  // Device input,output vectors
  float *d_a, *d_b, *d_c;

  // Size, in bytes, of each vector
  size_t bytes = N * sizeof(float);

  // Allocate host memory
  h_a = (float *)malloc(bytes);
  h_b = (float *)malloc(bytes);
  h_c = (float *)malloc(bytes);

  // Allocate memory for each vector on GPU
  cudaMalloc(&d_a, bytes);
  cudaMalloc(&d_b, bytes);
  cudaMalloc(&d_c, bytes);

  // Initialize vectors on host
  for (unsigned i = 0; i < N; i++) {
    h_a[i] = i + 1.0;
    h_b[i] = N - i - 1.0;
  }

  // Copy host vectors to device
  cudaMemcpy(d_a, h_a, bytes, cudaMemcpyHostToDevice);
  cudaMemcpy(d_b, h_b, bytes, cudaMemcpyHostToDevice);

  int blockSize, gridSize;

  // Number of threads in each thread block
  blockSize = 64;

  // Number of thread blocks in grid
  gridSize = (N + blockSize - 1) / blockSize;

  // Do a warm up run
  for (unsigned t = 0; t < 100; t++)
    vecAdd<<<gridSize, blockSize>>>(d_a, d_b, d_c, N);

  cudaDeviceSynchronize();

  // Time the vector addition
  clock_t t = clock();

  // Execute the kernel
  for (unsigned t = 0; t < trials; t++)
    vecAdd<<<gridSize, blockSize>>>(d_a, d_b, d_c, N);

  // block CPU execution until all previously issued commands on the device have
  // completed
  cudaDeviceSynchronize();

  t = clock() - t;
  // Copy array back to host
  cudaMemcpy(h_c, d_c, bytes, cudaMemcpyDeviceToHost);

  for (unsigned i = 0; i < N; i++)
    assert(fabs(h_c[i] - N) < 1e-8);

  printf("N: %u blockSize: %d gridSize: %d time %e\n", N, blockSize, gridSize,
         (double)t / (CLOCKS_PER_SEC * trials));

  // Release device memory
  cudaFree(d_a);
  cudaFree(d_b);
  cudaFree(d_c);

  // Release host memory
  free(h_a);
  free(h_b);
  free(h_c);

  return 0;
}
